#################################  creating dataframe
ID<-seq(1:10)
Response<-c(37.7, 24.2, 32.1,  3.6, 17.6, 45.9, 29.6,  8.1, 20.1, 13.0)
Predictor01<-c(1739, 1221, 1846,  120, 1096, 2290, 1687,  241,  649, 1427)
Predictor02<-c(9.3,  5.9,  8.8,  3.8, 10.3, 11.6,  9.0,  6.,  7.8, 10.9)
Predictor03<-c(85.4, 60.7, 68.1, 20.2, 33.8, 95.1, 69.3, 16.3, 34.9, 15.1)
Predictor04<-c(3.5, 5.0, 4.4, 4.0, 3.5, 4.1, 4.1, 5.9, 5.5, 4.1)
Predictor05<-c(9,  5,  7,  5,  7, 13, 15, 11, 16, 10)
DF<-data.frame(ID,Response,Predictor01,Predictor02,Predictor03,Predictor04,Predictor05)  
View(DF)

#################################  grouped scatterplot
library(tidyr)
library(ggplot2)
(gs<-DF[,-1] %>% gather(-`Response`,key=var,value="value") %>% 
    ggplot(aes(x=value,y=`Response`))+geom_point()+
    facet_wrap(~ var, scales="free")+theme_bw())
windows(20,10)
gs+labs(x="Predictor variables",y="Response variable")+
  geom_smooth(method="lm")+ # includes regression line
  theme(text = element_text(size=15))+
    coord_cartesian(ylim=c(0,50))+scale_y_continuous(breaks=seq(0,50,10))

#################################  Multiple linear regression
# Full model
fit1<-lm(Response~., data = DF[,-1])
summary(fit1)
#################################  Check for multi-collinearity
library(faraway)
(v1<-vif(fit1))

#################################  remove Predictor01
fit2<-lm(Response~., data = DF[,c(-1,-3)])
summary(fit2)
(v2<-vif(fit2))

#################################  standardised regression coefficients to compare coefficients
library(QuantPsyc)
src1<-lm.beta(fit1) # model 01
(src2<-lm.beta(fit2)) # model 02

######################################################################################
##############  sample output of overall result
Labels<-c("Overall","Intercept",
          "Predictor 02", "Predictor 03","Predictor 04","Predictor 05")
(output<-summary(fit2))

############## adjusted r squared
(r2<-output$adj.r.squared)
(r2_per<-paste0(round(r2*100,1),"%"))
(adj_r<-c(r2_per, rep("",5)))

################################# regression coefficients
(Coeff<-c("",round(coefficients(fit2),2)))

################################# 95% CI (lower)
(Lower<-c("","",round(confint(fit2, level=0.95)[-1,1],2)))
################################# 95% CI (upper)
(Upper<-c("","",round(confint(fit2, level=0.95)[-1,2],2)))

################################# standardised regression coefficients
(Stand_Coeff<-c("","",round(src2,2)))

################################ p-values
############## overall p-value
# https://stackoverflow.com/questions/5587676/pull-out-p-values-and-r-squared-from-a-linear-regression
lmp <- function (modelobject) {
  if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
  f <- summary(modelobject)$fstatistic
  p <- pf(f[1],f[2],f[3],lower.tail=F)
  attributes(p) <- NULL
  return(p)
}
(p<-ifelse(lmp(fit2)<0.0005,"<0.0005",round(lmp(fit2),4)))
############## individual p-values 
(pvalues<-c(p,"",
            ifelse(output$coefficients[-1,4]<0.0005,"<0.0005",round(output$coefficients[-1,4],4))))

################################# dataframe
(df<-data.frame(Labels,adj_r,Coeff,Lower,Upper,Stand_Coeff,pvalues))

################################# write to Excel
library(xlsx)
write.xlsx(df,"Table_MLR.xlsx")






